gpus: 1
distributed_backend: ddp
seed: 0
fast_dev_run: false
max_epochs: 100

image_net_path: ???
cifar10_path: ???
simple_shapes_path: ???

visual_dataset: "imagenet"

img_size: 32

n_validation_examples: 32

vae:
  batch_size: 128
  data_augmentation: true

  beta: 0.5
  z_size: 12
  ae_size: 512
  type: "optimal_sigma"

  n_FID_samples: 1000

  optim:
    lr: 1e-4
    weight_decay: 3e-5

  scheduler:
    step: 20
    gamma: 0.5

lm:
  z_size: 12

  batch_size: 128
  n_validation_examples: 32
  optim:
    lr: 1e-4
    weight_decay: 3e-5
  scheduler:
    step: 10
    gamma: 0.1

global_workspace:
  monitor_grad_norms: false  # if true, training is a bit slower.
  batch_size: 128
  data_augmentation: false
  selected_domains: { "v": "v", "t": "t" }

  use_pre_saved: false
  load_pre_saved_latents: null

  split_ood: false
  bert_path: "bert-base-uncased"

  z_size: 20
  hidden_size: 512
  prop_sync_domains:  # Nomenclature of names: <numberDomains>d<isActionPossible>a<hasDifferentTimes>t
    1d0a1t: 0.  # having only one domain (excluding actions)
    2d0a1t: 0.  # having two domains from same
    2d1a2t: 0.  # having two domains and an action with 2 temporality
    3d0a2t: 0.
    3d1a2t: 0.
    all: 1.  # all domain
  classes_labelled_images: null  # null is all classes
  vae_checkpoint: ???
  lm_checkpoint: ???
  vae_mmd_loss_coef: 0.
  vae_kl_loss_coef: 0.

  optim:
    lr:
      encoders: 1e-4
      decoders: 1e-4
      supervised_multiplier: 1.
      unsupervised_multiplier: 1.
    weight_decay: 3e-5

  scheduler:
    step: 20
    gamma: 0.5

losses:
  coefs:
    demi_cycles: 1.
    cycles: 1.
    supervision: 1.

gensim_model_path: ???
word_embeddings: null

dataloader:
  num_workers: 0

neptune:
  project_name: null
  api_token: null
  mode: async
  resume: null

checkpoints_dir: ???
resume_from_checkpoint: null
